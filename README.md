# OCR Layout Detection
![img](./img/inference.png)
## Подход:
Задачу можно сформулировать как минимум двумя способами:
* как задачу детекции областей с текстом и с изображениями
* как задачу сегментации с последующим построением детекций
Из общих соображений кажется, что для блоков текста и изображений подход с сегментацией должен рабоать лучше, аналогичные соображения в статье [[1]](https://link.springer.com/chapter/10.1007/978-3-319-95957-3_30). <br>
Базовую модель собрал по мотивам статьи [[1]](https://link.springer.com/chapter/10.1007/978-3-319-95957-3_30) (DeepLabV3). <br>
Параметры модели и размер изображения выбирался так, чтобы разделение между полигонами в масках не пропадало при ресайзе к размеру выхода модели (в данном случае `(600, 400)` - размер входного изображения,`(76, 51)` - размер маски на выходе модели). <br>
Далее:
1. Привел аннотации в train и test к одинаковому виду (в train аннотация полигонов была нормирована на размер изображения, в test - аннотация в пикселях).
2. Использовал аугментации без искажений изображения, т-к желаемые границы полигонов всегда прямые.
3. Обучил модель с кросс энтропией в качестве функции потерь. На валидации вычислялся `mIoU`, сохранялась модель с минимальным значением `1 - mIoU`.
4. Посчитал IoU по маскам та тестовой выборке, отдельно для каждого класса.
5. Попробовал улучшить IoU с постобработкой диляцией и эрозией с квадратным ядром (не помогло).
6. Построил боксы по семантическим маскам.
Detection of text and images layout with DeepLabv3.
* [Ноутбук с обучением]("./train.ipynb").
* [Ноутбук с инференсом и метриками]("./report.ipynb").
* [Веса](https://drive.google.com/file/d/1K5vsi_Y6hiDlpyarJ8GysZ0IMkzXTGX0/view?usp=sharing).
 
---
 
# Гипотезы по улучшению:
## Дополнительный лосс
1. Минимизация разницы площадей прямоугольного бокса вокруг сегментированной области и площади области - штрафует сегментацию отличную по форме от горизонтального прямоугольника.
2. Минимизация угла поворота первых двух главных осей сегментированной области относительно вертикальной оси.
3. Consistency loss из [[1]](https://link.springer.com/chapter/10.1007/978-3-319-95957-3_30).
 
## Аугментации
1. Добавить любые цветовые аугментации.
2. Случайные кропы без поворотов.
3. Возможно сработают аугментации MixUp и Mosaic.
4. Должен сработать CutOut.
5. Попробовать более сложные аугментации, например [[2]](https://arxiv.org/pdf/2108.09929.pdf), [[3]](https://openaccess.thecvf.com/content/WACV2021/papers/Olsson_ClassMix_Segmentation-Based_Data_Augmentation_for_Semi-Supervised_Learning_WACV_2021_paper.pdf).
 
## Постобработка
1. Попробовать постобработку из [[1]](https://link.springer.com/chapter/10.1007/978-3-319-95957-3_30) (CRF, CCA, RLSA)
2. Применить диляцию и эрозию с прямоугольным ядром.
3. Отфильтровывать боксы внутри других боксов и боксы с маленькой площадью.
 
## Альтернативные подходы
1. Решать задачу как регрессию ключевых точек полигонов.
2. Фоновые пиксели всегда похожи на сетку, можно выполнять сегментацию только фоновых пикселей и классифицировать области окруженные фоновыми пикселями. При сегментации фоновых пикселей может дать прирост лосс ориентированный на подобную структуру сегментируемой области [[4]](https://arxiv.org/pdf/2003.07311.pdf) или [[5]](https://arxiv.org/pdf/2103.09992v1.pdf).
 
## Архитектура модели
1. Увеличить размер выхода модели, использовать транспонированные свертки.
2. Попробовать LayoutLMv3 [[6]](https://arxiv.org/pdf/2204.08387v2.pdf).
3. Попробовать VisualWordGrid [[7]](https://arxiv.org/pdf/2010.02358v5.pdf).

